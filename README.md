# ðŸš€ Awesome Time Series Explanation Papers

A curated list of papers on **time series explanation / interpretability**. 
This repository aims to help researchers and practitioners quickly navigate the growing literature in this field.

We will try our best to make this paper list updated. If you notice some related papers missing, do not hesitate to contact usðŸ¤—.

## ðŸ”–Table of Contents
- [Surveys](#Surveys)
- [Papers](#Papers)
  - [2025](#2025)
  - [2024](#2024)
  - [2023](#2023)
  - [2022](#2022)
  - [2021](#2021)
  - [2020](#2020)
  - [2019&before](#2019&before)

## ðŸ“˜Surveys

### 2023

Interpretation of Time-Series Deep Models: A Survey [[link]](https://arxiv.org/pdf/2305.14582) 

### 2022

Explainable AI for Time Series Classification: A review, taxonomy and research directions [[link]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9895252)

Post Hoc Explainability for Time Series Classification [[link]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9810094)

Counterfactual explanations and how to find them: literature review and benchmarking [[link]](https://link.springer.com/content/pdf/10.1007/s10618-022-00831-6.pdf)

### 2021

Explainable Artificial Intelligence (XAI) on Time Series Data: A Survey [[link]](https://arxiv.org/pdf/2104.00950)

## ðŸ“œPapers

### 2025

1. [ICLR 25]Start Smart: Leveraging Gradients For Enhancing Mask-based XAI Methods [[link]](https://openreview.net/pdf?id=Iht4NNVqk0)

2. [ICLR 25]Shedding Light on Time Series Classification using Interpretability Gated Networks [[link]](https://openreview.net/pdf?id=n34taxF0TC)

3. [AAAI 25]InteDisUX: Intepretation-Guided Discriminative User-Centric Explanation for Time Series [[link]](https://ojs.aaai.org/index.php/AAAI/article/view/35387)

4. [ICML 25]TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation [[link]](https://arxiv.org/pdf/2506.05035)

5. [ICML 25]Optimal Information Retention for Time-Series Explanations [[link]](https://openreview.net/pdf?id=u6k5y3FDW1)

6. [ICML Workshop 25]DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values [[link]](https://arxiv.org/pdf/2507.02342)

7. Explanation Space: A New Perspective into Time Series Interpretability [[link]](https://arxiv.org/pdf/2409.01354)

8. FLEXtime: Filterbank learning to explain time series [[link]](https://arxiv.org/pdf/2411.05841)

9. Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop [[link]](https://arxiv.org/pdf/2503.01013)

10. TF-LIME : Interpretation Method for Time-Series Models Based on Timeâ€“Frequency Features [[link]](https://www.mdpi.com/1424-8220/25/9/2845)

11. On the Necessity of Multi-Domain Explanation: An Uncertainty Principle Approach for Deep Time Series Models [[link]](https://arxiv.org/pdf/2506.03267) 

12. Implet: A Post-hoc Subsequence Explainer for Time Series Models [[link]](https://arxiv.org/pdf/2505.08748)

### 2024

1. [ICLR 24]Explaining Time Series via Contrastive and Locally Sparse Perturbations [[link]](https://openreview.net/pdf?id=qDdSRaOiyb)

2. [ICLR 24]Inherently Interpretable Time Series Classification via Multiple Instance Learning [[link]](https://arxiv.org/pdf/2311.10049)

3. [ICML 24]TIMEX++: Learning Time-Series Explanations with Information Bottleneck [[link]](https://arxiv.org/abs/2405.09308)

4. [CIKM 24]Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models  [[link]](https://arxiv.org/pdf/2408.03636)

5. Glacier: guided locally constrained counterfactual explanations forÂ time series classification [[link]](https://link.springer.com/content/pdf/10.1007/s10994-023-06502-x.pdf)

6. Sub-SpaCE: Subsequence-Based Sparse Counterfactual Explanations forÂ Time Series Classification Problems [[link]](https://link.springer.com/chapter/10.1007/978-3-031-63800-8_1)

7. ShapTime: A General XAI Approach for Explainable Time Series Forecasting [[link]](https://link.springer.com/chapter/10.1007/978-3-031-47721-8_45)

8. IndMask: Inductive Explanation for Multivariate Time Series Black-Box Models [[link]](https://pdfs.semanticscholar.org/72f6/873b03f8ec549011dfca3dc4ae7a7adc7451.pdf)

### 2023

1. [ICLR 23]Temporal Dependencies in Feature Importance for Time Series Prediction [[link]](https://arxiv.org/pdf/2107.14317)

2. [ICML 23]Learning Perturbations to Explain Time Series Predictions [[link]](https://arxiv.org/pdf/2305.18840)

3. [ICML 23]Self-Interpretable Time Series Prediction with Counterfactual Explanations [[link]](https://openreview.net/pdf?id=JPMT9kjeJi)

4. [NIPS 23]Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency [[link]](https://openreview.net/pdf?id=yEfmhgwslQ)

5. Explaining time series classifiers through meaningful perturbation and optimization [[link]](https://www.sciencedirect.com/science/article/pii/S0020025523009192?via%3Dihub)

6. CELS: Counterfactual Explanations for Time Series Data via Learned Saliency Maps [[link]](https://ieeexplore.ieee.org/abstract/document/10386229)

7. Explainable AI for Time Series via Virtual Inspection Layers [[link]](https://arxiv.org/pdf/2303.06365)

### 2022

1. [ICDM 22]Class-Specific Explainability for Deep Time Series Classifiers [[link]](https://arxiv.org/pdf/2210.05411)

2. [ICDM 22]Neuro-symbolic models for interpretable time series classification using temporal logic description [[link]](https://arxiv.org/pdf/2209.09114)

3. [AISTATS 22]LIMESegment: Meaningful, Realistic Time Series Explanation [[link]](https://proceedings.mlr.press/v151/sivill22a/sivill22a.pdf)

4. Shapelet-Based Counterfactual Explanations for Multivariate Time Series [[link]](https://arxiv.org/pdf/2208.10462)

5. XEM: An Explainable-by-Design Ensemble Method for Multivariate Time Series Classification [[link]](https://arxiv.org/pdf/2005.03645)

### 2021

1. [ICML 21]Explaining time series predictions with dynamic masks [[link]](https://arxiv.org/pdf/2106.05303)

2. [KDD 21]TimeSHAP: Explaining Recurrent Models through Sequence Perturbations [[link]](https://arxiv.org/pdf/2012.00073)

3. [CIKM 21] Learning saliency maps to explain deep time series classifier [[link]](https://dl.acm.org/doi/pdf/10.1145/3459637.3482446)

4. Temporal Fusion Transformers for interpretable multi-horizon time series forecasting [[link]](https://www.sciencedirect.com/science/article/pii/S0169207021000637)

5. Counterfactual Explanations for Multivariate Time Series [[link]](https://ieeexplore.ieee.org/document/9462056)

6. XCM: An Explainable Convolutional Neural Network for Multivariate Time Series Classification [[link]](https://arxiv.org/pdf/2009.04796)

7. Instance-based Counterfactual Explanations for Time Series Classification [[link]](https://arxiv.org/pdf/2009.13211)

### 2020

1. [NIPS 20]Benchmarking Deep Learning Interpretability in Time Series Predictions [[link]](https://arxiv.org/pdf/2010.13924)

2. [ICLR 20]N-BEATS: Neural basis expansion analysis for interpretable time series forecasting [[link]](https://arxiv.org/pdf/1905.10437)

3. [NIPS 20] What went wrong and when? Instance-wise feature importance for time-series black-box models [[link]](https://arxiv.org/pdf/2003.02821)

4. [KDD 20]Preserving dynamic attention for long-term spatial-temporal prediction [[link]](https://arxiv.org/pdf/2006.08849)

5. Explaining Any Time Series Classifier [[link]](https://ieeexplore.ieee.org/document/9319285)

6. Interpretable Multivariate Time Series Forecasting with Temporal Attention Convolutional Neural Networks [[link]](https://ieeexplore.ieee.org/document/9308570)

7. Series Saliency: Temporal Interpretation for Multivariate Time Series Forecasting [[link]](https://arxiv.org/abs/2012.09324)

### 2019&before

1. [ICML 19]Exploring Interpretable LSTM Neural Networks over Multi-Variable Data [[link]](https://arxiv.org/pdf/1905.12034)

2. [ICDM 19]MTEX-CNN: Multivariate Time Series EXplanations for Predictions with Convolutional Neural Networks [[link]](https://ieeexplore.ieee.org/document/8970899)

3. [ICTAI 19]Explainable ai for time series via virtual inspection layer [[link]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8995349)

4. [ICML 17]Learning important features through propagating activation differences [[link]](https://arxiv.org/pdf/1704.02685)

5. [NIPS 16]Retain: An interpretable predictive model for healthcare using reverse time attention mechanism [[link]](https://arxiv.org/abs/1608.05745)